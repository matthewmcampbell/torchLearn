{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e6a877e",
   "metadata": {},
   "source": [
    "# Building a Basic Image Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06e5217e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "datapath = \"./data/cifar10/\"\n",
    "cifar10 = datasets.CIFAR10(datapath, train=True, download=True)\n",
    "cifar10_val = datasets.CIFAR10(datapath, train=False, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e95999f",
   "metadata": {},
   "source": [
    "## Examine what a Torch Dataset object consists of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aeb963eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'root, transform, target_transform, transforms, train, data, targets, classes, class_to_idx, __module__, __doc__, base_folder, url, filename, tgz_md5, train_list, test_list, meta, __init__, _load_meta, __getitem__, __len__, _check_integrity, download, extra_repr, __parameters__, _repr_indent, __repr__, _format_transform_repr, __add__, __orig_bases__, __dict__, __weakref__, __slots__, _is_protocol, __new__, __class_getitem__, __init_subclass__, __hash__, __str__, __getattribute__, __setattr__, __delattr__, __lt__, __le__, __eq__, __ne__, __gt__, __ge__, __reduce_ex__, __reduce__, __subclasshook__, __format__, __sizeof__, __dir__, __class__'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "', '.join([attr for attr in cifar10.__dir__()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8955daf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'airplane': 0,\n",
       " 'automobile': 1,\n",
       " 'bird': 2,\n",
       " 'cat': 3,\n",
       " 'deer': 4,\n",
       " 'dog': 5,\n",
       " 'frog': 6,\n",
       " 'horse': 7,\n",
       " 'ship': 8,\n",
       " 'truck': 9}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar10.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f9e2ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['frog',\n",
       " 'truck',\n",
       " 'truck',\n",
       " 'deer',\n",
       " 'automobile',\n",
       " 'automobile',\n",
       " 'bird',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'horse',\n",
       " 'horse',\n",
       " 'bird',\n",
       " 'truck',\n",
       " 'truck',\n",
       " 'truck',\n",
       " 'cat',\n",
       " 'bird',\n",
       " 'frog',\n",
       " 'deer',\n",
       " 'cat',\n",
       " 'frog',\n",
       " 'frog',\n",
       " 'bird',\n",
       " 'frog',\n",
       " 'cat',\n",
       " 'dog',\n",
       " 'deer',\n",
       " 'airplane',\n",
       " 'airplane',\n",
       " 'truck',\n",
       " 'automobile',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'airplane',\n",
       " 'cat',\n",
       " 'horse',\n",
       " 'cat',\n",
       " 'cat',\n",
       " 'dog',\n",
       " 'bird',\n",
       " 'bird',\n",
       " 'horse',\n",
       " 'automobile',\n",
       " 'automobile',\n",
       " 'automobile',\n",
       " 'bird',\n",
       " 'bird',\n",
       " 'airplane',\n",
       " 'truck',\n",
       " 'dog',\n",
       " 'horse',\n",
       " 'truck',\n",
       " 'bird',\n",
       " 'bird',\n",
       " 'dog',\n",
       " 'bird',\n",
       " 'deer',\n",
       " 'cat',\n",
       " 'automobile',\n",
       " 'automobile',\n",
       " 'ship',\n",
       " 'bird',\n",
       " 'automobile',\n",
       " 'automobile',\n",
       " 'deer',\n",
       " 'truck',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'dog',\n",
       " 'truck',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'cat',\n",
       " 'automobile',\n",
       " 'truck',\n",
       " 'airplane',\n",
       " 'cat',\n",
       " 'automobile',\n",
       " 'cat',\n",
       " 'dog',\n",
       " 'deer',\n",
       " 'dog',\n",
       " 'horse',\n",
       " 'horse',\n",
       " 'deer',\n",
       " 'horse',\n",
       " 'truck',\n",
       " 'deer',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'ship',\n",
       " 'airplane',\n",
       " 'automobile',\n",
       " 'frog',\n",
       " 'automobile',\n",
       " 'automobile',\n",
       " 'deer',\n",
       " 'automobile',\n",
       " 'ship',\n",
       " 'cat',\n",
       " 'truck',\n",
       " 'frog',\n",
       " 'frog',\n",
       " 'automobile',\n",
       " 'ship',\n",
       " 'dog',\n",
       " 'bird',\n",
       " 'truck',\n",
       " 'truck',\n",
       " 'ship',\n",
       " 'automobile',\n",
       " 'horse',\n",
       " 'horse',\n",
       " 'airplane',\n",
       " 'airplane',\n",
       " 'frog',\n",
       " 'truck',\n",
       " 'automobile',\n",
       " 'bird',\n",
       " 'bird',\n",
       " 'truck',\n",
       " 'bird',\n",
       " 'frog',\n",
       " 'frog',\n",
       " 'automobile',\n",
       " 'truck',\n",
       " 'dog',\n",
       " 'airplane',\n",
       " 'deer',\n",
       " 'horse',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'automobile',\n",
       " 'ship',\n",
       " 'automobile',\n",
       " 'automobile',\n",
       " 'bird',\n",
       " 'ship',\n",
       " 'automobile',\n",
       " 'cat',\n",
       " 'cat',\n",
       " 'frog',\n",
       " 'bird',\n",
       " 'deer',\n",
       " 'truck',\n",
       " 'truck',\n",
       " 'dog',\n",
       " 'deer',\n",
       " 'cat',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'deer',\n",
       " 'frog',\n",
       " 'ship',\n",
       " 'dog',\n",
       " 'dog',\n",
       " 'deer',\n",
       " 'cat',\n",
       " 'automobile',\n",
       " 'ship',\n",
       " 'deer',\n",
       " 'horse',\n",
       " 'frog',\n",
       " 'airplane',\n",
       " 'truck',\n",
       " 'dog',\n",
       " 'automobile',\n",
       " 'cat',\n",
       " 'ship',\n",
       " 'bird',\n",
       " 'horse',\n",
       " 'dog',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'automobile',\n",
       " 'dog',\n",
       " 'horse',\n",
       " 'airplane',\n",
       " 'deer',\n",
       " 'horse',\n",
       " 'dog',\n",
       " 'dog',\n",
       " 'automobile',\n",
       " 'airplane',\n",
       " 'truck',\n",
       " 'frog',\n",
       " 'truck',\n",
       " 'airplane',\n",
       " 'ship',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'ship',\n",
       " 'bird',\n",
       " 'dog',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'dog',\n",
       " 'airplane',\n",
       " 'frog',\n",
       " 'automobile',\n",
       " 'truck',\n",
       " 'cat',\n",
       " 'frog',\n",
       " 'truck',\n",
       " 'automobile',\n",
       " 'cat',\n",
       " 'truck',\n",
       " 'frog',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'automobile',\n",
       " 'airplane',\n",
       " 'truck',\n",
       " 'dog',\n",
       " 'ship',\n",
       " 'dog',\n",
       " 'bird',\n",
       " 'truck',\n",
       " 'airplane',\n",
       " 'ship',\n",
       " 'ship',\n",
       " 'airplane',\n",
       " 'frog',\n",
       " 'truck',\n",
       " 'automobile',\n",
       " 'automobile',\n",
       " 'frog',\n",
       " 'cat',\n",
       " 'horse',\n",
       " 'frog',\n",
       " 'frog',\n",
       " 'airplane',\n",
       " 'frog',\n",
       " 'frog',\n",
       " 'automobile',\n",
       " 'horse',\n",
       " 'automobile',\n",
       " 'dog',\n",
       " 'ship',\n",
       " 'cat',\n",
       " 'frog',\n",
       " 'frog',\n",
       " 'ship',\n",
       " 'frog',\n",
       " 'ship',\n",
       " 'deer',\n",
       " 'frog',\n",
       " 'frog',\n",
       " 'automobile',\n",
       " 'cat',\n",
       " 'ship',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'automobile',\n",
       " 'horse',\n",
       " 'automobile',\n",
       " 'cat',\n",
       " 'ship',\n",
       " 'dog',\n",
       " 'automobile',\n",
       " 'automobile',\n",
       " 'deer',\n",
       " 'airplane',\n",
       " 'truck',\n",
       " 'cat',\n",
       " 'horse',\n",
       " 'deer',\n",
       " 'truck',\n",
       " 'truck',\n",
       " 'bird',\n",
       " 'deer',\n",
       " 'truck',\n",
       " 'truck',\n",
       " 'automobile',\n",
       " 'airplane',\n",
       " 'dog',\n",
       " 'truck',\n",
       " 'airplane',\n",
       " 'ship',\n",
       " 'bird',\n",
       " 'automobile',\n",
       " 'bird',\n",
       " 'airplane',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'cat',\n",
       " 'bird',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'ship',\n",
       " 'frog',\n",
       " 'airplane',\n",
       " 'horse',\n",
       " 'truck',\n",
       " 'deer',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'deer',\n",
       " 'bird',\n",
       " 'automobile',\n",
       " 'automobile',\n",
       " 'bird',\n",
       " 'automobile',\n",
       " 'dog',\n",
       " 'truck',\n",
       " 'truck',\n",
       " 'airplane',\n",
       " 'ship',\n",
       " 'deer',\n",
       " 'automobile',\n",
       " 'automobile',\n",
       " 'frog',\n",
       " 'cat',\n",
       " 'cat',\n",
       " 'truck',\n",
       " 'airplane',\n",
       " 'horse',\n",
       " 'truck',\n",
       " 'horse',\n",
       " 'horse',\n",
       " 'truck',\n",
       " 'automobile',\n",
       " 'dog',\n",
       " 'automobile',\n",
       " 'frog',\n",
       " 'frog',\n",
       " 'ship',\n",
       " 'horse',\n",
       " 'automobile',\n",
       " 'cat',\n",
       " 'airplane',\n",
       " 'cat',\n",
       " 'cat',\n",
       " 'bird',\n",
       " 'deer',\n",
       " 'dog',\n",
       " 'horse',\n",
       " 'dog',\n",
       " 'truck',\n",
       " 'airplane',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'airplane',\n",
       " 'deer',\n",
       " 'deer',\n",
       " 'frog',\n",
       " 'airplane',\n",
       " 'airplane',\n",
       " 'frog',\n",
       " 'frog',\n",
       " 'airplane',\n",
       " 'ship',\n",
       " 'automobile',\n",
       " 'frog',\n",
       " 'bird',\n",
       " 'truck',\n",
       " 'bird',\n",
       " 'dog',\n",
       " 'truck',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'deer',\n",
       " 'automobile',\n",
       " 'ship',\n",
       " 'horse',\n",
       " 'cat',\n",
       " 'frog',\n",
       " 'truck',\n",
       " 'cat',\n",
       " 'airplane',\n",
       " 'deer',\n",
       " 'airplane',\n",
       " 'dog',\n",
       " 'automobile',\n",
       " 'airplane',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'ship',\n",
       " 'dog',\n",
       " 'deer',\n",
       " 'horse',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'truck',\n",
       " 'horse',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'automobile',\n",
       " 'deer',\n",
       " 'horse',\n",
       " 'airplane',\n",
       " 'automobile',\n",
       " 'horse',\n",
       " 'cat',\n",
       " 'automobile',\n",
       " 'ship',\n",
       " 'deer',\n",
       " 'deer',\n",
       " 'bird',\n",
       " 'airplane',\n",
       " 'bird',\n",
       " 'bird',\n",
       " 'airplane',\n",
       " 'airplane',\n",
       " 'truck',\n",
       " 'airplane',\n",
       " 'truck',\n",
       " 'frog',\n",
       " 'ship',\n",
       " 'bird',\n",
       " 'horse',\n",
       " 'horse',\n",
       " 'deer',\n",
       " 'airplane',\n",
       " 'cat',\n",
       " 'airplane',\n",
       " 'ship',\n",
       " 'truck',\n",
       " 'deer',\n",
       " 'bird',\n",
       " 'horse',\n",
       " 'bird',\n",
       " 'dog',\n",
       " 'bird',\n",
       " 'dog',\n",
       " 'automobile',\n",
       " 'truck',\n",
       " 'deer',\n",
       " 'ship',\n",
       " 'dog',\n",
       " 'automobile',\n",
       " 'horse',\n",
       " 'deer',\n",
       " 'deer',\n",
       " 'airplane',\n",
       " 'frog',\n",
       " 'truck',\n",
       " 'airplane',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'ship',\n",
       " 'truck',\n",
       " 'truck',\n",
       " 'cat',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'airplane',\n",
       " 'deer',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'frog',\n",
       " 'airplane',\n",
       " 'automobile',\n",
       " 'airplane',\n",
       " 'ship',\n",
       " 'airplane',\n",
       " 'deer',\n",
       " 'ship',\n",
       " 'ship',\n",
       " 'automobile',\n",
       " 'dog',\n",
       " 'bird',\n",
       " 'frog',\n",
       " 'ship',\n",
       " 'automobile',\n",
       " 'airplane',\n",
       " 'airplane',\n",
       " 'horse',\n",
       " 'horse',\n",
       " 'dog',\n",
       " 'truck',\n",
       " 'frog',\n",
       " 'bird',\n",
       " 'ship',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'horse',\n",
       " 'cat',\n",
       " 'truck',\n",
       " 'airplane',\n",
       " 'automobile',\n",
       " 'bird',\n",
       " 'deer',\n",
       " 'ship',\n",
       " 'automobile',\n",
       " 'ship',\n",
       " 'frog',\n",
       " 'deer',\n",
       " 'deer',\n",
       " 'dog',\n",
       " 'horse',\n",
       " 'automobile',\n",
       " 'cat',\n",
       " 'truck',\n",
       " 'ship',\n",
       " 'airplane',\n",
       " 'automobile',\n",
       " 'horse',\n",
       " 'dog',\n",
       " 'ship',\n",
       " 'bird',\n",
       " 'ship',\n",
       " 'airplane',\n",
       " 'deer',\n",
       " 'automobile',\n",
       " 'ship',\n",
       " 'truck',\n",
       " 'ship',\n",
       " 'bird',\n",
       " 'truck',\n",
       " 'truck',\n",
       " 'bird',\n",
       " 'horse',\n",
       " 'dog',\n",
       " 'horse',\n",
       " 'cat',\n",
       " 'ship',\n",
       " 'ship',\n",
       " 'deer',\n",
       " 'deer',\n",
       " 'bird',\n",
       " 'horse',\n",
       " 'automobile',\n",
       " 'frog',\n",
       " 'deer',\n",
       " 'airplane',\n",
       " 'deer',\n",
       " 'frog',\n",
       " 'truck',\n",
       " 'horse',\n",
       " 'frog',\n",
       " 'bird',\n",
       " 'dog',\n",
       " 'dog',\n",
       " 'automobile',\n",
       " 'horse',\n",
       " 'bird',\n",
       " 'bird',\n",
       " 'bird',\n",
       " 'truck',\n",
       " 'dog',\n",
       " 'deer',\n",
       " 'bird',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'automobile',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'cat',\n",
       " 'horse',\n",
       " 'frog',\n",
       " 'truck',\n",
       " 'ship',\n",
       " 'airplane',\n",
       " 'frog',\n",
       " 'airplane',\n",
       " 'bird',\n",
       " 'bird',\n",
       " 'bird',\n",
       " 'automobile',\n",
       " 'ship',\n",
       " 'deer',\n",
       " 'airplane',\n",
       " 'automobile',\n",
       " 'ship',\n",
       " 'ship',\n",
       " 'automobile',\n",
       " 'dog',\n",
       " 'horse',\n",
       " 'frog',\n",
       " 'deer',\n",
       " 'dog',\n",
       " 'ship',\n",
       " 'horse',\n",
       " 'automobile',\n",
       " 'truck',\n",
       " 'automobile',\n",
       " 'truck',\n",
       " 'ship',\n",
       " 'deer',\n",
       " 'horse',\n",
       " 'cat',\n",
       " 'ship',\n",
       " 'ship',\n",
       " 'bird',\n",
       " 'frog',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'automobile',\n",
       " 'frog',\n",
       " 'ship',\n",
       " 'automobile',\n",
       " 'truck',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'cat',\n",
       " 'airplane',\n",
       " 'automobile',\n",
       " 'airplane',\n",
       " 'ship',\n",
       " 'ship',\n",
       " 'cat',\n",
       " 'airplane',\n",
       " 'airplane',\n",
       " 'automobile',\n",
       " 'dog',\n",
       " 'airplane',\n",
       " 'ship',\n",
       " 'ship',\n",
       " 'horse',\n",
       " 'truck',\n",
       " 'truck',\n",
       " 'airplane',\n",
       " 'truck',\n",
       " 'deer',\n",
       " 'automobile',\n",
       " 'cat',\n",
       " 'frog',\n",
       " 'frog',\n",
       " 'deer',\n",
       " 'deer',\n",
       " 'horse',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'airplane',\n",
       " 'ship',\n",
       " 'airplane',\n",
       " 'cat',\n",
       " 'bird',\n",
       " 'ship',\n",
       " 'deer',\n",
       " 'frog',\n",
       " 'truck',\n",
       " 'truck',\n",
       " 'horse',\n",
       " 'airplane',\n",
       " 'cat',\n",
       " 'cat',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'deer',\n",
       " 'truck',\n",
       " 'automobile',\n",
       " 'frog',\n",
       " 'bird',\n",
       " 'horse',\n",
       " 'bird',\n",
       " 'bird',\n",
       " 'airplane',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'dog',\n",
       " 'horse',\n",
       " 'frog',\n",
       " 'ship',\n",
       " 'truck',\n",
       " 'airplane',\n",
       " 'truck',\n",
       " 'deer',\n",
       " 'deer',\n",
       " 'horse',\n",
       " 'airplane',\n",
       " 'truck',\n",
       " 'deer',\n",
       " 'truck',\n",
       " 'frog',\n",
       " 'truck',\n",
       " 'deer',\n",
       " 'dog',\n",
       " 'horse',\n",
       " 'truck',\n",
       " 'bird',\n",
       " 'deer',\n",
       " 'dog',\n",
       " 'automobile',\n",
       " 'deer',\n",
       " 'cat',\n",
       " 'truck',\n",
       " 'frog',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'truck',\n",
       " 'cat',\n",
       " 'cat',\n",
       " 'dog',\n",
       " 'airplane',\n",
       " 'horse',\n",
       " 'bird',\n",
       " 'automobile',\n",
       " 'cat',\n",
       " 'frog',\n",
       " 'deer',\n",
       " 'airplane',\n",
       " 'airplane',\n",
       " 'bird',\n",
       " 'dog',\n",
       " 'airplane',\n",
       " 'automobile',\n",
       " 'airplane',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'truck',\n",
       " 'ship',\n",
       " 'deer',\n",
       " 'truck',\n",
       " 'ship',\n",
       " 'airplane',\n",
       " 'bird',\n",
       " 'frog',\n",
       " 'deer',\n",
       " 'deer',\n",
       " 'airplane',\n",
       " 'automobile',\n",
       " 'ship',\n",
       " 'ship',\n",
       " 'cat',\n",
       " 'frog',\n",
       " 'truck',\n",
       " 'frog',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'bird',\n",
       " 'deer',\n",
       " 'dog',\n",
       " 'horse',\n",
       " 'frog',\n",
       " 'dog',\n",
       " 'cat',\n",
       " 'airplane',\n",
       " 'dog',\n",
       " 'airplane',\n",
       " 'dog',\n",
       " 'airplane',\n",
       " 'ship',\n",
       " 'bird',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'cat',\n",
       " 'ship',\n",
       " 'bird',\n",
       " 'automobile',\n",
       " 'horse',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'automobile',\n",
       " 'airplane',\n",
       " 'truck',\n",
       " 'dog',\n",
       " 'dog',\n",
       " 'airplane',\n",
       " 'automobile',\n",
       " 'horse',\n",
       " 'frog',\n",
       " 'truck',\n",
       " 'airplane',\n",
       " 'deer',\n",
       " 'horse',\n",
       " 'horse',\n",
       " 'automobile',\n",
       " 'dog',\n",
       " 'truck',\n",
       " 'deer',\n",
       " 'airplane',\n",
       " 'ship',\n",
       " 'dog',\n",
       " 'truck',\n",
       " 'truck',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'automobile',\n",
       " 'ship',\n",
       " 'cat',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'ship',\n",
       " 'bird',\n",
       " 'bird',\n",
       " 'deer',\n",
       " 'frog',\n",
       " 'airplane',\n",
       " 'airplane',\n",
       " 'dog',\n",
       " 'cat',\n",
       " 'ship',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'horse',\n",
       " 'bird',\n",
       " 'truck',\n",
       " 'cat',\n",
       " 'ship',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'bird',\n",
       " 'horse',\n",
       " 'truck',\n",
       " 'airplane',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'bird',\n",
       " 'bird',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'cat',\n",
       " 'frog',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'bird',\n",
       " 'ship',\n",
       " 'airplane',\n",
       " 'dog',\n",
       " 'dog',\n",
       " 'automobile',\n",
       " 'deer',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'frog',\n",
       " 'bird',\n",
       " 'horse',\n",
       " 'airplane',\n",
       " 'automobile',\n",
       " 'horse',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'bird',\n",
       " 'truck',\n",
       " 'bird',\n",
       " 'bird',\n",
       " 'deer',\n",
       " 'bird',\n",
       " 'automobile',\n",
       " 'automobile',\n",
       " 'automobile',\n",
       " 'frog',\n",
       " 'frog',\n",
       " 'frog',\n",
       " 'dog',\n",
       " 'automobile',\n",
       " 'automobile',\n",
       " 'horse',\n",
       " 'airplane',\n",
       " 'deer',\n",
       " 'cat',\n",
       " 'cat',\n",
       " 'horse',\n",
       " 'automobile',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'dog',\n",
       " 'dog',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'automobile',\n",
       " 'deer',\n",
       " 'cat',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'ship',\n",
       " 'cat',\n",
       " 'frog',\n",
       " 'frog',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'airplane',\n",
       " 'truck',\n",
       " 'deer',\n",
       " 'cat',\n",
       " 'ship',\n",
       " 'airplane',\n",
       " 'airplane',\n",
       " 'automobile',\n",
       " 'automobile',\n",
       " 'dog',\n",
       " 'deer',\n",
       " 'truck',\n",
       " 'cat',\n",
       " 'automobile',\n",
       " 'ship',\n",
       " 'truck',\n",
       " 'cat',\n",
       " 'truck',\n",
       " 'truck',\n",
       " 'bird',\n",
       " 'truck',\n",
       " 'deer',\n",
       " 'ship',\n",
       " 'bird',\n",
       " 'truck',\n",
       " 'ship',\n",
       " 'ship',\n",
       " 'automobile',\n",
       " 'dog',\n",
       " 'cat',\n",
       " 'frog',\n",
       " 'ship',\n",
       " 'horse',\n",
       " 'frog',\n",
       " 'truck',\n",
       " 'ship',\n",
       " 'airplane',\n",
       " 'frog',\n",
       " 'deer',\n",
       " 'airplane',\n",
       " 'airplane',\n",
       " 'bird',\n",
       " 'dog',\n",
       " 'ship',\n",
       " 'bird',\n",
       " 'airplane',\n",
       " 'bird',\n",
       " 'horse',\n",
       " 'frog',\n",
       " 'truck',\n",
       " 'horse',\n",
       " 'automobile',\n",
       " 'dog',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'frog',\n",
       " 'cat',\n",
       " 'frog',\n",
       " 'bird',\n",
       " 'deer',\n",
       " 'horse',\n",
       " 'airplane',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'deer',\n",
       " 'frog',\n",
       " 'dog',\n",
       " 'bird',\n",
       " 'deer',\n",
       " 'frog',\n",
       " 'automobile',\n",
       " 'frog',\n",
       " 'airplane',\n",
       " 'deer',\n",
       " 'airplane',\n",
       " 'cat',\n",
       " 'automobile',\n",
       " 'ship',\n",
       " 'dog',\n",
       " 'deer',\n",
       " 'deer',\n",
       " 'automobile',\n",
       " 'horse',\n",
       " 'cat',\n",
       " 'truck',\n",
       " 'deer',\n",
       " 'horse',\n",
       " 'truck',\n",
       " 'horse',\n",
       " 'cat',\n",
       " 'horse',\n",
       " 'bird',\n",
       " 'ship',\n",
       " 'deer',\n",
       " 'frog',\n",
       " 'frog',\n",
       " 'automobile',\n",
       " 'bird',\n",
       " 'truck',\n",
       " 'airplane',\n",
       " 'deer',\n",
       " 'ship',\n",
       " 'horse',\n",
       " 'cat',\n",
       " 'truck',\n",
       " 'ship',\n",
       " 'horse',\n",
       " 'horse',\n",
       " 'airplane',\n",
       " 'bird',\n",
       " 'deer',\n",
       " 'automobile',\n",
       " 'automobile',\n",
       " 'deer',\n",
       " 'automobile',\n",
       " 'dog',\n",
       " 'deer',\n",
       " 'airplane',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'bird',\n",
       " 'ship',\n",
       " 'dog',\n",
       " 'airplane',\n",
       " 'bird',\n",
       " 'automobile',\n",
       " 'cat',\n",
       " 'dog',\n",
       " 'horse',\n",
       " 'cat',\n",
       " 'dog',\n",
       " 'automobile',\n",
       " 'cat',\n",
       " 'dog',\n",
       " ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_class = {cifar10.class_to_idx[idx]: idx for idx in cifar10.class_to_idx}\n",
    "[idx_to_class[target] for target in cifar10.targets]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d148ed",
   "metadata": {},
   "source": [
    "## Display one of the images for sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8633b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img, label = cifar10[99]\n",
    "plt.imshow(img)\n",
    "print(f\"{label}: {idx_to_class[label]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de253543",
   "metadata": {},
   "source": [
    "## But for image classification, we need a tensor represenation (C x H x W layout) of the image data. We'll apply a transform across the whole dataset for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1aa139d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "to_tensor = transforms.ToTensor()\n",
    "tensor_cifar10 = datasets.CIFAR10(datapath, train=True, download=True, transform = to_tensor)\n",
    "img_tensor, label = tensor_cifar10[99]\n",
    "img_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad042818",
   "metadata": {},
   "source": [
    "## It's also important that our NN inputs are scaled to [0, 1]; transforms.ToTensor() should've already taken care of this, but let's verify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "552a37b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.), tensor(1.))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_tensor.min(), img_tensor.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851f8662",
   "metadata": {},
   "source": [
    "## For the sake of practice, let's standardize instead of normalize our data. This is a little confusing, as Torch's Normalize function is actually for standardizing, but the terminology is a little loose across disciplines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "735aeaae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32, 50000])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_imgs = torch.stack([img_tensor for img_tensor, _ in tensor_cifar10], dim=3)\n",
    "all_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "105814b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.4914, 0.4822, 0.4465]), tensor([0.2470, 0.2435, 0.2616]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the mean, std for each different RGB channel.\n",
    "mean = all_imgs.view(3, -1).mean(dim=1)\n",
    "std = all_imgs.view(3, -1).std(dim=1)\n",
    "mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1236629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_pipeline = transforms.Compose([\n",
    "    to_tensor,\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "transformed_cifar10 = datasets.CIFAR10(datapath, train=True, download=True, transform = transform_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2b038f",
   "metadata": {},
   "source": [
    "## But what has this transformation _actually_ done to our image represenation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a67b6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1da61a3ee0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_t, _ = transformed_cifar10[99]\n",
    "plt.imshow(img_t.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa79cb21",
   "metadata": {},
   "source": [
    "#### Since we standardized instead of normalized to [0, 1], RGB data falling outside the range of [0, 1] gets clipped by matplotlib, hence the black portions in the image. All of our data still exists within the tensor, however."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e175ff",
   "metadata": {},
   "source": [
    "## Next, let's build a binary classifier that can distinguish birds from planes. These are two of the existing labels in CIFAR10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cd3a099",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {0: 0, 2: 1} # convert CIFAR10 labels for our own purposes.\n",
    "class_names = [idx_to_class[label] for label in label_map.keys()]\n",
    "cifar2 = [(img, label_map[label])\n",
    "          for img, label in cifar10\n",
    "          if label in [0, 2]]\n",
    "cifar2_val = [(img, label_map[label])\n",
    "              for img, label in cifar10_val\n",
    "              if label in [0, 2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2097a3",
   "metadata": {},
   "source": [
    "#### Note that the above is a bit of a hack; cifar2 is a simple list of tuples, whereas cifar10 is a torch Dataset class. In a production setting, it's probably worth subclassing Dataset for better Torch integration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e6242f",
   "metadata": {},
   "source": [
    "## On to a naive deep model. We'll start out with the (somewhat silly) assumption that each pixel is unrelated; i.e., no convolutions. Each pixel will be its own feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77eeae82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=3072, out_features=512, bias=True)\n",
       "  (1): Tanh()\n",
       "  (2): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (3): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "input_dim = img_t.reshape(-1, 1).shape[0]\n",
    "output_dim = len(label_map)\n",
    "\n",
    "hidden_dim = 512\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(input_dim, hidden_dim),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(hidden_dim, output_dim),\n",
    "    nn.Softmax(dim=1))\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e6d6c7",
   "metadata": {},
   "source": [
    "### Let's try running the model before any training, just to see what happens. First, let's take an image from our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bf01034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, _ = cifar2[0]\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3e26592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before reshape: torch.Size([3, 32, 32])\n",
      "After reshape: torch.Size([1, 3072])\n"
     ]
    }
   ],
   "source": [
    "dummy_img_test = transform_pipeline(img)\n",
    "print(f\"Before reshape: {dummy_img_test.shape}\")\n",
    "img_test = dummy_img_test.reshape(1, -1)\n",
    "print(f\"After reshape: {img_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ac2a09c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4895, 0.5105]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "untrained_output = model(img_test)\n",
    "untrained_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac29ca9",
   "metadata": {},
   "source": [
    "## The above is quite meaningless. Two probabilities (in the sense that the values sum to 1 and are non-negative) that don't correspond to classes. Next step is to actually train the model.\n",
    "\n",
    "## First, let's glance at how our negative-log-likelihood gets computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ce5ad76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9713, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nn.NLLLoss()\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(input_dim, hidden_dim),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(hidden_dim, output_dim),\n",
    "    nn.LogSoftmax(dim=1))\n",
    "\n",
    "img, label = cifar2[0]\n",
    "output = model(transform_pipeline(img).reshape(1, -1))\n",
    "loss(output, torch.tensor([label]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ddf144",
   "metadata": {},
   "source": [
    "## Now on to the training (finally):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c0eab2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transformed_cifar10 = datasets.CIFAR10(datapath, train=True, download=True, transform = transform_pipeline)\n",
    "transformed_cifar10_val = datasets.CIFAR10(datapath, train=False, download=True, transform = transform_pipeline)\n",
    "\n",
    "cifar2 = [(img, label_map[label])\n",
    "          for img, label in transformed_cifar10\n",
    "          if label in [0, 2]]\n",
    "cifar2_val = [(img, label_map[label])\n",
    "              for img, label in transformed_cifar10_val\n",
    "              if label in [0, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17a68151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9. Loss 0.5566878914833069\n",
      "Epoch 19. Loss 0.18045447766780853\n",
      "Epoch 29. Loss 0.11467021703720093\n",
      "Epoch 39. Loss 0.05060455948114395\n",
      "Epoch 49. Loss 0.07783043384552002\n",
      "Epoch 59. Loss 0.12021815031766891\n",
      "Epoch 69. Loss 0.06101994961500168\n",
      "Epoch 79. Loss 0.03293102979660034\n",
      "Epoch 89. Loss 0.018272290006279945\n",
      "Epoch 99. Loss 0.016706256195902824\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    cifar2, batch_size=64, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    cifar2_val, batch_size=64, shuffle=True)\n",
    "\n",
    "lr = 1e-2\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "loss_fn = nn.NLLLoss()\n",
    "n_epochs = 100\n",
    "\n",
    "\n",
    "def train_model(model, loss_fn, optimizer, n_epochs):\n",
    "    for epoch in range(n_epochs):\n",
    "        for imgs, labels in train_loader:\n",
    "            batch_size = imgs.shape[0]\n",
    "            outputs = model(imgs.reshape(batch_size, -1))\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch}. Loss {loss}\")\n",
    "train_model(model, loss_fn, optimizer, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2beb0810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8245\n"
     ]
    }
   ],
   "source": [
    "val_loader = torch.utils.data.DataLoader(\n",
    "    cifar2_val, batch_size=64, shuffle=True)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        batch_size = imgs.shape[0]\n",
    "        outputs = model(imgs.reshape(batch_size, -1))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "print(f\"Accuracy: {float(correct/total)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887e97fe",
   "metadata": {},
   "source": [
    "## The above is not wildly impressive, but at least a good start. With a binary classification task including this many samples, we can probably do better.\n",
    "\n",
    "## Let's make our model a bit more expressive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c9fb7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9. Loss 0.26207399368286133\n",
      "Epoch 19. Loss 0.2484678030014038\n",
      "Epoch 29. Loss 0.490213006734848\n",
      "Epoch 39. Loss 0.3140726089477539\n",
      "Epoch 49. Loss 0.007724680006504059\n",
      "Epoch 59. Loss 0.010667456313967705\n",
      "Epoch 69. Loss 0.0067721083760261536\n",
      "Epoch 79. Loss 0.009544343687593937\n",
      "Epoch 89. Loss 0.0025051722768694162\n",
      "Epoch 99. Loss 0.01217687875032425\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(input_dim, 1024),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(1024, 512),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(512, 128),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(128, output_dim))\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "train_model(model, loss_fn, optimizer, n_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6c3e32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.793\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        batch_size = imgs.shape[0]\n",
    "        outputs = model(imgs.reshape(batch_size, -1))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "print(f\"Accuracy: {float(correct/total)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691ba2db",
   "metadata": {},
   "source": [
    "## Well, well. Our validation accuracy got even worse! That's not too surprising: we're well into the territory of _overfitting_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8565d12",
   "metadata": {},
   "source": [
    "## Instead of trying to reduce the above overfitting issue, let's switch gears to a less naive model: CNNs (conv nets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de82e718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = nn.Conv2d(3, 16, kernel_size=3)\n",
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "596dcc34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 3, 3, 3]), torch.Size([16]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.weight.shape, conv.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb822b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 32, 32]), torch.Size([1, 3, 16, 16]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool = nn.MaxPool2d(2)\n",
    "img_in = transform_pipeline(img)\n",
    "output = pool(img_in.unsqueeze(0))\n",
    "img_in.shape, output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4752ab27",
   "metadata": {},
   "source": [
    "## As practice, we'll build out the CNN via subclassing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46e26c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.act1 = nn.Tanh()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.act2 = nn.Tanh()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(8*8*8, 32)\n",
    "        self.act3 = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.pool1(self.act1(self.conv1(x)))\n",
    "        out = self.pool2(self.act2(self.conv2(out)))\n",
    "        out = out.reshape(-1, 8*8*8)\n",
    "        out = self.act3(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ebee911d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18090, [432, 16, 1152, 8, 16384, 32, 64, 2])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN()\n",
    "numel_list = [p.numel() for p in model.parameters()]\n",
    "sum(numel_list), numel_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b23b87b",
   "metadata": {},
   "source": [
    "## But we could also define our module more \"functionally\" in Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8265bb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN_functional(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(8*8*8, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = out.reshape(-1, 8*8*8)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdbca17",
   "metadata": {},
   "source": [
    "### Testing to make sure both of the above can run..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8434fda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 32, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0067, 0.0337]], grad_fn=<AddmmBackward>),\n",
       " tensor([[0.0600, 0.0294]], grad_fn=<AddmmBackward>))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = CNN()\n",
    "model2 = CNN_functional()\n",
    "\n",
    "test = img_in.unsqueeze(0)\n",
    "print(test.shape)\n",
    "model1(test), model2(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1fbfd7",
   "metadata": {},
   "source": [
    "## Now let's build out a training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e1679b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-08 06:55:46.466087. Epoch: 1, Training Loss: 0.5725577071214177\n",
      "2022-02-08 06:55:52.427670. Epoch: 10, Training Loss: 0.3302003230638565\n",
      "2022-02-08 06:55:58.956198. Epoch: 20, Training Loss: 0.2904417769164796\n",
      "2022-02-08 06:56:05.475709. Epoch: 30, Training Loss: 0.2663229017690488\n",
      "2022-02-08 06:56:12.006944. Epoch: 40, Training Loss: 0.24894204090355307\n",
      "2022-02-08 06:56:18.514733. Epoch: 50, Training Loss: 0.23171078110006965\n",
      "2022-02-08 06:56:25.029610. Epoch: 60, Training Loss: 0.21815557697206545\n",
      "2022-02-08 06:56:31.531160. Epoch: 70, Training Loss: 0.20302774913751395\n",
      "2022-02-08 06:56:38.041947. Epoch: 80, Training Loss: 0.1889920921842004\n",
      "2022-02-08 06:56:44.782591. Epoch: 90, Training Loss: 0.17352291168111145\n",
      "2022-02-08 06:56:51.309863. Epoch: 100, Training Loss: 0.16005158868090363\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime as dt\n",
    "\n",
    "def training_loop(\n",
    "        n_epochs,\n",
    "        optimizer,\n",
    "        model,\n",
    "        loss_fn,\n",
    "        train_loader):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "            \n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_train += loss.item()\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print(f\"{dt.now()}. Epoch: {epoch}, Training Loss: {loss_train/len(train_loader)}\")\n",
    "\n",
    "n_epochs = 100            \n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=True)\n",
    "model = CNN_functional()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs,\n",
    "    optimizer,\n",
    "    model,\n",
    "    loss_fn,\n",
    "    train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a96b624",
   "metadata": {},
   "source": [
    "## But who cares about training loss! Let's check out accuracy of prediction (and use a validation set while we're at it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7ab22e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: 0.9417\n",
      "validation: 0.885\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64, shuffle=False)\n",
    "\n",
    "def validate(model, train_loader, val_loader):\n",
    "    for name, loader in [(\"training\", train_loader), (\"validation\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for imgs, labels in loader:\n",
    "            total += labels.shape[0]\n",
    "            _, outputs = torch.max(model(imgs), dim=1) # torch.max returns max_value, index\n",
    "            correct += int((outputs == labels).sum())\n",
    "        print(f\"{name}: {correct/total}\")\n",
    "\n",
    "validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe490cf6",
   "metadata": {},
   "source": [
    "## Much better than our naive model. There would still be plenty of hyper-parameter fitting to do (n_epochs, filter sizes, NN architecture, etc), but we will leave that to another day. On to bigger and better things!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
